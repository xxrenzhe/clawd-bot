---
title: "Moltbot Load Balancing: Scale for High Traffic [2026]"
description: "Load balance Moltbot instances for high traffic. Configure Nginx, HAProxy, sticky sessions, health checks, and high-availability setups."
pubDate: 2026-01-27
modifiedDate: 2026-01-29
category: "Advanced"
tags: ["moltbot","clawdbot","load balancing","scaling","high availability","nginx"]
keywords: ["moltbot load balancing","clawdbot scaling","nginx proxy","haproxy","high availability", "openclaw"]
readingTime: 8
featured: false
author: "Moltbot Team"
image: "/images/articles/clawdbot-load-balancing.jpg"
imageAlt: "Moltbot Load Balancing"
articleType: "TechArticle"
difficulty: "advanced"
sources:
  - "https://docs.molt.bot/"
  - "https://github.com/moltbot/moltbot"
relatedArticles:
  - "clawdbot-scalability"
  - "clawdbot-monitoring-setup"
  - "clawdbot-reverse-proxy"
---
import HostingCTA from '../../components/CTA/HostingCTA.astro';

# Moltbot Load Balancing: Scale for High Traffic

![Moltbot Load Balancing](/images/articles/clawdbot-load-balancing.jpg)

## Load Balancer Options

| Option | Best For | Complexity |
|--------|----------|------------|
| Nginx | Small-medium scale | Low |
| HAProxy | High performance | Medium |
| Traefik | Kubernetes/Docker | Medium |
| Cloud LB | AWS/GCP/Azure | Low |

<HostingCTA context="setup" />

## Architecture

```
                    ┌─────────────┐
                    │   Client    │
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │ Load Balancer│
                    └──────┬──────┘
           ┌───────────────┼───────────────┐
           │               │               │
    ┌──────▼──────┐ ┌──────▼──────┐ ┌──────▼──────┐
    │  Moltbot 1  │ │  Moltbot 2  │ │  Moltbot 3  │
    └──────┬──────┘ └──────┬──────┘ └──────┬──────┘
           │               │               │
           └───────────────┼───────────────┘
                    ┌──────▼──────┐
                    │    Redis    │
                    └─────────────┘
```

<HostingCTA context="inline" />

## Nginx Configuration

### Basic Load Balancing

```nginx
upstream moltbot {
    least_conn;
    server 10.0.1.10:18789 weight=1;
    server 10.0.1.11:18789 weight=1;
    server 10.0.1.12:18789 weight=1;
}

server {
    listen 80;
    server_name moltbot.example.com;

    location / {
        proxy_pass http://moltbot;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 300s;
    }
}
```

### Sticky Sessions

```nginx
upstream moltbot {
    ip_hash;
    server 10.0.1.10:18789;
    server 10.0.1.11:18789;
    server 10.0.1.12:18789;
}
```

Or cookie-based:

```nginx
upstream moltbot {
    hash $cookie_moltbot_session consistent;
    server 10.0.1.10:18789;
    server 10.0.1.11:18789;
    server 10.0.1.12:18789;
}
```

### Health Checks

```nginx
upstream moltbot {
    least_conn;
    server 10.0.1.10:18789 max_fails=3 fail_timeout=30s;
    server 10.0.1.11:18789 max_fails=3 fail_timeout=30s;
    server 10.0.1.12:18789 max_fails=3 fail_timeout=30s;
}
```

For active health checks (Nginx Plus or OpenResty):

```nginx
upstream moltbot {
    zone moltbot 64k;
    server 10.0.1.10:18789;
    server 10.0.1.11:18789;

    health_check interval=5s passes=2 fails=3 uri=/health;
}
```

## HAProxy Configuration

```haproxy
global
    maxconn 4096
    log /dev/log local0

defaults
    mode http
    timeout connect 5s
    timeout client 50s
    timeout server 300s
    option httplog
    option dontlognull

frontend moltbot_front
    bind *:80
    default_backend moltbot_back

backend moltbot_back
    balance leastconn
    option httpchk GET /health
    http-check expect status 200

    cookie SERVERID insert indirect nocache

    server moltbot1 10.0.1.10:18789 check cookie s1
    server moltbot2 10.0.1.11:18789 check cookie s2
    server moltbot3 10.0.1.12:18789 check cookie s3

listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 30s
```

## Traefik (Docker/Kubernetes)

### Docker Labels

```yaml
services:
  moltbot:
    image: moltbot/moltbot:latest
    deploy:
      replicas: 3
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.moltbot.rule=Host(`moltbot.example.com`)"
      - "traefik.http.services.moltbot.loadbalancer.sticky.cookie=true"
      - "traefik.http.services.moltbot.loadbalancer.sticky.cookie.name=moltbot_server"
      - "traefik.http.services.moltbot.loadbalancer.healthcheck.path=/health"
      - "traefik.http.services.moltbot.loadbalancer.healthcheck.interval=10s"
```

### Kubernetes IngressRoute

```yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: moltbot
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`moltbot.example.com`)
      kind: Rule
      services:
        - name: moltbot
          port: 18789
          sticky:
            cookie:
              name: moltbot_server
              secure: true
              httpOnly: true
```

## Shared State with Redis

Moltbot instances need shared state for session consistency:

```json
{
  "gateway": {
    "state": {
      "type": "redis",
      "url": "redis://redis:6379",
      "prefix": "moltbot:"
    },
    "sessions": {
      "store": "redis",
      "ttl": 86400
    }
  }
}
```

## Load Balancing Algorithms

| Algorithm | Use Case | Pros | Cons |
|-----------|----------|------|------|
| Round Robin | Equal servers | Simple | No session affinity |
| Least Connections | Variable load | Better distribution | No affinity |
| IP Hash | Session affinity | Sticky sessions | Uneven with NAT |
| Cookie Hash | Best affinity | True persistence | Cookie overhead |

## Auto-Scaling

### Docker Compose

```yaml
services:
  moltbot:
    image: moltbot/moltbot:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
```

Scale manually:
```bash
docker-compose up -d --scale moltbot=5
```

### Kubernetes HPA

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: moltbot
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: moltbot
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

## Monitoring

### Nginx Status

```nginx
location /nginx_status {
    stub_status on;
    allow 127.0.0.1;
    deny all;
}
```

### HAProxy Stats

Access `http://lb:8404/stats` for real-time metrics.

### Metrics to Watch

| Metric | Warning | Critical |
|--------|---------|----------|
| Response time | >2s | >5s |
| Error rate | >1% | >5% |
| CPU per instance | >70% | >90% |
| Active connections | >80% capacity | >95% |

## Troubleshooting

| Issue | Cause | Solution |
|-------|-------|----------|
| Session loss | No sticky sessions | Enable cookie affinity |
| Uneven load | Wrong algorithm | Use least_conn |
| 502 errors | Backend down | Check health checks |
| High latency | Overloaded | Add more instances |

### Debug Commands

```bash
# Check upstream health (Nginx)
curl -s http://localhost/nginx_status

# Test specific backend
curl -H "Host: moltbot.example.com" http://10.0.1.10:18789/health

# HAProxy stats via socket
echo "show stat" | socat stdio /var/run/haproxy.sock
```

## Next Steps

- [Scalability guide](/articles/clawdbot-scalability)
- [Monitoring setup](/articles/clawdbot-monitoring-setup)
- [Reverse proxy setup](/articles/clawdbot-reverse-proxy)

<HostingCTA context="conclusion" />
