---
title: "Deploying Moltbot: Docker, Kubernetes, and Cloud Options"
description: "Learn how to deploy Moltbot (Clawdbot/Openclaw) using Docker, Kubernetes, and major cloud providers. A comprehensive guide for self-hosting your private AI gateway."
pubDate: 2026-02-01
modifiedDate: 2026-02-01
category: "Tutorial"
tags: ["moltbot deployment","docker","kubernetes","cloud deployment"]
keywords: ["moltbot deployment","docker","kubernetes","cloud deployment","openclaw","openclaw","moltbot","clawdbot"]
readingTime: 12
featured: false
author: "Moltbot Team"
image: "/images/articles/deploying-moltbot-docker-kubernetes-and-cloud-options.jpg"
imageAlt: "Deploying Moltbot: Docker, Kubernetes, and Cloud Options"
articleType: "HowTo"
difficulty: "beginner"
sources:
  - "https://docs.molt.bot/"
  - "https://github.com/clawdbot/clawdbot"
---

import HostingCTA from '../../components/CTA/HostingCTA.astro';

In the rapidly evolving landscape of artificial intelligence, the bridge between your data and Large Language Models (LLMs) is often the most critical link. Moltbot, also known as Clawdbot or Openclaw, is an open-source, self-hosted personal AI assistant designed to serve as your private AI gateway. Unlike centralized platforms, Moltbot gives you total control over your persistent memory, messaging platform integrations, and computer access tools.

Whether you are looking to run a private instance on your local machine or scale a robust gateway for a team, understanding the deployment options is essential. This guide walks you through the technical steps of deploying Moltbot using Docker, Kubernetes, and various cloud providers, ensuring your AI remains secure, accessible, and fast.

<HostingCTA context="setup" />

## Why Self-Host Moltbot?

Moltbot (Openclaw) is built on the philosophy of data sovereignty. By self-hosting, you ensure that:
1. **Privacy:** Your chat logs and file-based memories never leave your controlled environment.
2. **Persistence:** Use file-based memory that persists across sessions and restarts.
3. **Integration:** Connect seamlessly with Telegram, Discord, Slack, and WhatsApp without third-party middleware.
4. **Flexibility:** Swap between Claude, GPT-4, or even local models via Ollama at the configuration level.

## Prerequisites

Before diving into the specific deployment methods, ensure you have the following ready:
- A server or local machine with at least 2GB of RAM (4GB recommended).
- An API key from a provider like Anthropic (Claude) or OpenAI.
- Basic familiarity with the command line.
- A registered domain name (optional, but recommended for cloud deployments).

## Method 1: The Quick Start Shell Installation

For those who want to get up and running in minutes on a Linux or macOS machine, the official installation script is the fastest path. This method installs the `clawdbot` CLI tool directly on your host.

### Step 1: Run the Install Script
Open your terminal and execute:

```bash
curl -fsSL https://clawd.bot/install.sh | bash
```

This script detects your architecture and installs the latest binary.

### Step 2: Onboarding
Once installed, run the onboarding command to set up your environment variables and API keys:

```bash
clawdbot onboard
```

### Step 3: Verify Installation
Run a health check to ensure all components are functioning correctly:

```bash
clawdbot health
```

Finally, start the gateway:

```bash
clawdbot gateway --port 18789 --verbose
```

## Method 2: Deploying with Docker and Docker Compose

Docker is the preferred method for most users who want to isolate Moltbot from their host operating system while maintaining easy updates and portability.

### The Dockerfile Logic
While the official image is available on Docker Hub, a typical `docker-compose.yml` for Clawdbot/Moltbot looks like this:

```yaml
version: '3.8'

services:
  moltbot:
    image: clawdbot/clawdbot:latest
    container_name: moltbot-gateway
    restart: unless-stopped
    ports:
      - "18789:18789"
    volumes:
      - ./data:/home/clawdbot/.clawdbot
      - ./config:/etc/clawdbot
    environment:
      - CLAWDBOT_GATEWAY_PORT=18789
      - CLAWDBOT_AUTH_PASSWORD=${YOUR_SECURE_PASSWORD}
      - ANTHROPIC_API_KEY=${YOUR_ANTHROPIC_KEY}
      - OPENAI_API_KEY=${YOUR_OPENAI_KEY}
    networks:
      - moltbot-net

networks:
  moltbot-net:
    driver: bridge
```

### Key Configuration Parameters
- **Persistence:** The volume mapping `./data:/home/clawdbot/.clawdbot` is crucial. This is where Moltbot stores its file-based memory and learned skills.
- **Port Mapping:** The default port is `18789`. You can change this, but ensure your firewall allows traffic through it.

### Deployment Steps
1. Create a directory: `mkdir moltbot && cd moltbot`.
2. Save the YAML above as `docker-compose.yml`.
3. Create an `.env` file with your keys.
4. Run `docker-compose up -d`.

<HostingCTA context="inline" />

## Method 3: Scaling with Kubernetes

For enterprise environments or developers who prefer high availability, deploying Moltbot to a Kubernetes (K8s) cluster provides advanced scaling and self-healing capabilities.

### Deployment Manifest
Create a file named `moltbot-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: moltbot
  labels:
    app: moltbot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: moltbot
  template:
    metadata:
      labels:
        app: moltbot
    spec:
      containers:
      - name: moltbot
        image: clawdbot/clawdbot:latest
        ports:
        - containerPort: 18789
        env:
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: anthropic
        volumeMounts:
        - name: moltbot-storage
          mountPath: /home/clawdbot/.clawdbot
      volumes:
      - name: moltbot-storage
        persistentVolumeClaim:
          claimName: moltbot-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: moltbot-service
spec:
  selector:
    app: moltbot
  ports:
    - protocol: TCP
      port: 80
      targetPort: 18789
  type: LoadBalancer
```

### Why Kubernetes?
In a K8s setup, if the Moltbot pod crashes, the controller automatically restarts it. By using a `PersistentVolumeClaim` (PVC), you ensure that your AI’s "memory" stays intact even if the pod is rescheduled to a different node.

## Cloud Deployment Options

If you don't want to manage hardware, several cloud providers offer "one-click" or simple CLI deployments that work perfectly with Openclaw/Moltbot.

### 1. DigitalOcean (Droplets)
DigitalOcean is excellent for beginners. You can spin up a "Docker on Ubuntu" Droplet and follow the Docker Compose instructions above.
- **Cost:** ~$6/month.
- **Setup:** Use the Marketplace "Docker" image.

### 2. AWS (EC2 or ECS)
For more complex needs, AWS provides Elastic Container Service (ECS).
- **Security Groups:** Ensure you open port 18789 only to your specific IP address or through a Load Balancer.
- **Storage:** Use EFS (Elastic File System) if you need to share the Moltbot memory across multiple instances.

### 3. Fly.io
Fly.io is great for running apps close to your users. Since Moltbot is a single binary/container, it deploys very easily using `fly launch`.

## Critical Security Best Practices

When deploying Moltbot (Clawdbot) to the public web, security is paramount. Since this gateway has access to your LLM credits and potentially your local files, follow these steps:

### 1. Bind to Loopback
In your `config.yaml` or environment variables, set the gateway bind address to `127.0.0.1` if you are using a reverse proxy (like Nginx or Caddy). This prevents direct external access to the port.

### 2. Enable Pairing Mode
Configure the DM (Direct Message) policy to use "pairing" mode. This requires you to manually approve any new device or account that attempts to communicate with your Moltbot instance.

### 3. Gateway Authentication
Always set a `gateway.auth.password`. This ensures that even if someone finds your endpoint, they cannot use your gateway without the secret.

### 4. Trusted Proxies
If you are using a reverse proxy, configure `gateway.trustedProxies` to include your proxy's IP. This ensures Moltbot correctly identifies the client's original IP address for logging and security.

## Post-Deployment: Connecting Messaging Apps

Once Moltbot is running, you'll want to connect it to your preferred chat application. Moltbot supports:
- **Telegram:** Create a bot via @BotFather and provide the token to Moltbot.
- **Discord:** Create an application in the Discord Developer Portal.
- **Slack/WhatsApp:** Follow the specific plugin documentation in the `clawdbot` repository.

To verify your configuration at any time, run:
```bash
clawdbot health
```
This will tell you which integrations are active and if the gateway is reaching the LLM providers successfully.

## Conclusion

Deploying Moltbot (Clawdbot/Openclaw) transforms a standard LLM into a powerful, personalized, and private assistant. Whether you choose the simplicity of a shell script, the portability of Docker, or the scalability of Kubernetes, the core benefit remains the same: complete control over your AI.

By following the security best practices—especially around binding and pairing—you can enjoy the benefits of a persistent AI gateway without compromising your data safety.

We offer a free Moltbot installation service at [Contact](/contact) if you need professional assistance in setting up your instance on any of these platforms.

<HostingCTA context="conclusion" />